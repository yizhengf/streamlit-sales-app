import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import re
from datetime import datetime

def read_file(file):
    """
    @param {file} file - ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
    @return {DataFrame} - è¯»å–çš„æ•°æ®æ¡†
    """
    try:
        df = pd.read_csv(file, sep='\t')
        if len(df.columns) == 1:
            file.seek(0)
            df = pd.read_csv(file)
        return df
    except Exception as e:
        st.error(f"Error reading file {file.name}: {str(e)}")
        return None

def parse_date(date_str):
    """
    è§£ææ—¥æœŸå­—ç¬¦ä¸²ï¼Œè¿”å›å¹´ä»½ã€æœˆä»½å’Œæ—¥æœŸ
    """
    if not date_str:  # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
        return None, None, None

    month_abbr = {
        'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04',
        'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08',
        'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'
    }
    
    for abbr, month_num in month_abbr.items():
        if abbr in date_str:
            year_match = re.search(r'\b(\d{4})\b', date_str)
            hour_match = re.search(r'(\d{1,2}):\d{2}:\d{2} (AM|PM)', date_str)
            if year_match and hour_match:
                year = year_match.group(1)
                hour = int(hour_match.group(1))
                if hour_match.group(2) == 'PM' and hour != 12:
                    hour += 12  # PMä¸”ä¸æ˜¯12ç‚¹ï¼Œè½¬æ¢ä¸º24å°æ—¶åˆ¶
                elif hour_match.group(2) == 'AM' and hour == 12:
                    hour = 0  # AMä¸”æ˜¯12ç‚¹ï¼Œè½¬æ¢ä¸º0ç‚¹
                return year, month_num, date_str, hour  # è¿”å›åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²å’Œå°æ—¶
            else:
                return None, month_num, date_str, None
            
    return None, None, date_str, None

def process_data(df):
    """
    å¤„ç†æ•°æ®ï¼Œç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®å¹¶è®¡ç®—é”€å”®é¢
    """
    # ç¡®ä¿ quantity åˆ—ä¸ºæ•°å€¼ç±»å‹
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')  # å°†æ— æ³•è½¬æ¢çš„å€¼è®¾ç½®ä¸º NaN

    # ç¡®ä¿ product-sales åˆ—ä¸ºæ•°å€¼ç±»å‹
    df['product-sales'] = pd.to_numeric(df['product-sales'], errors='coerce')  # å°†æ— æ³•è½¬æ¢çš„å€¼è®¾ç½®ä¸º NaN

    # æ£€æŸ¥æ˜¯å¦æœ‰ NaN å€¼
    if df['quantity'].isnull().any() or df['product-sales'].isnull().any():
        st.warning("Warning: Some rows contain NaN values in 'quantity' or 'product-sales'. These rows will be dropped.")

    # åˆ é™¤åŒ…å« NaN çš„è¡Œ
    df = df.dropna(subset=['quantity', 'product-sales'])

    # è®¡ç®—é”€å”®é¢
    df['sales_amount'] = df['quantity'] * df['product-sales']  # è®¡ç®—é”€å”®é¢
    st.write(df.head())

    # æ£€æŸ¥ sales_amount åˆ—æ˜¯å¦æˆåŠŸåˆ›å»º
    if 'sales_amount' not in df.columns:
        st.error("Sales amount calculation failed. Please check your data.")
        st.write(df.head())  # è¾“å‡º DataFrame çš„å‰å‡ è¡Œä»¥ä¾¿è°ƒè¯•
        return df  # è¿”å›æœªä¿®æ”¹çš„ DataFrame
    return df

def parse_purchase_date(date_str):
    """
    è§£æ purchase-date å­—ç¬¦ä¸²ï¼Œè¿”å›æ—¥æœŸå’Œå°æ—¶
    """
    try:
        # è§£ææ ¼å¼ä¸º 'Jan 16, 2024 8:35:49 AM PST'
        date_obj = datetime.strptime(date_str, '%b %d, %Y %I:%M:%S %p %Z')
        return date_obj.date(), date_obj.hour  # è¿”å›æ—¥æœŸå’Œå°æ—¶
    except ValueError:
        return None, None  # å¦‚æœæ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¿”å› None


def extract_year_month(df):
    """
    ä» purchase-date åˆ—ä¸­æå–å¹´ä»½å’Œæœˆä»½
    """
    years = []
    months = []
    for date_str in df['purchase-date']:
        date_obj = parse_purchase_date(date_str)
        if date_obj:
            years.append(date_obj.year)
            months.append(date_obj.month)
        else:
            years.append(None)
            months.append(None)
    return years, months

def main():
    st.set_page_config(page_title="product-sales Analysis", layout="wide")
    st.title('product-sales Analysis')
    
    try:
        uploaded_files = st.sidebar.file_uploader(
            "Upload TSV/CSV files", 
            type=['txt', 'tsv', 'csv'],
            accept_multiple_files=True
        )
        
        if not uploaded_files:
            st.info('ğŸ‘† Please upload TSV or CSV files')
            return
            
        df_list = []
        for file in uploaded_files:
            df = read_file(file)
            if df is not None:
                df_list.append(df)
        
        if not df_list:
            st.error("No valid files were uploaded")
            return
            
        # åˆå¹¶æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶æ•°æ®
        df = pd.concat(df_list, ignore_index=True)
        # æå–æ—¥æœŸå’Œå°æ—¶ä¿¡æ¯
        df['purchase-date'] = df['purchase-date'].astype(str)  # ç¡®ä¿ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        df['date'], df['hour'] = zip(*df['purchase-date'].apply(parse_purchase_date))  # æå–æ—¥æœŸå’Œå°æ—¶

        # å¤„ç†æ•°æ®å¹¶è®¡ç®—é”€å”®é¢
        df = process_data(df)

        # æ£€æŸ¥ sales_amount åˆ—æ˜¯å¦å­˜åœ¨
        if 'sales_amount' not in df.columns:
            st.error("Sales amount calculation failed. Please check your data.")
            return

        # ç¡®ä¿ quantity åˆ—ä¸ºæ•°å€¼ç±»å‹
        df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')

        date_column = 'date/time' if 'date/time' in df.columns else 'purchase-date'
        
        # å¤„ç†æ—¥æœŸï¼Œä½¿ç”¨æ‰‹åŠ¨è§£æ
        years = []
        months = []
        days = []
        hours= []
        
        for date_str in df[date_column].astype(str):
            year, month, original_date, hour = parse_date(date_str)
            years.append(year)
            months.append(month)
            days.append(original_date)  # ç›´æ¥ä½¿ç”¨åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²
            hours.append(hour)

        df['year'] = years
        df['month_only'] = months
        df['date'] = days  # ä¿ç•™åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²
        df['hour_only'] = hours # ä¿ç•™å°æ—¶

        # æ£€æŸ¥æ˜¯å¦æœ‰æœªè§£æçš„æ—¥æœŸ
        if None in df['year'] or None in df['month_only']:
            st.warning("Some dates could not be parsed. Please check the date format in your files.")
        
        # æ£€æŸ¥ SKU æ ¼å¼
        df['sku'] = df['sku'].astype(str).str.strip()
        df['sku'] = df['sku'].apply(lambda x: 'S-' + x if x[0].isdigit() else x)

        # å¤„ç† product-name åˆ—ï¼Œè‹¥ä»¥æ•°å­—å¼€å¤´åˆ™æ ¹æ® store åˆ—çš„å€¼è¿›è¡Œå¤„ç†
        def process_product_name(row):
            if row['product-name'] and row['product-name'][0].isdigit():
                return f"{row['store']}-{row['product-name']}"
            return row['product-name']

        df['product-name'] = df.apply(process_product_name, axis=1)

        # ç¡®ä¿ quantity åˆ—ä¸ºæ•°å€¼ç±»å‹
        df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')

        # å°† type åˆ—ä¸­çš„æ‰€æœ‰æ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹
        df['type'] = df['type'].astype(str)

        st.sidebar.header('Filter Options')
        
        # å¹´ä»½ä¸‹æ‹‰é€‰æ‹©
        available_years = sorted(df['year'].unique())
        selected_years = st.sidebar.selectbox(
            "Select Year",
            options=available_years,
            index=0  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå¹´ä»½
        )
        
        # SKU ä¸‹æ‹‰é€‰æ‹©
        available_skus = sorted(df['sku'].unique())
        selected_skus = st.sidebar.multiselect(
            "Select SKUs to Analyze",
            options=available_skus,
            default=available_skus[:5]  # é»˜è®¤é€‰æ‹©å‰ 5 ä¸ª SKU
        )
        
        # æœˆä»½ç­›é€‰
        available_months = sorted(df['month_only'].unique())
        selected_months = st.sidebar.multiselect(
            "Select Months",
            options=available_months,
            default=available_months  # é»˜è®¤é€‰æ‹©æ‰€æœ‰æœˆä»½
        )
        
        # äº§å“åç§°æœç´¢æ¡†ï¼ŒåŒ…å«ä¸‹æ‹‰é€‰é¡¹
        product_name_search = st.sidebar.text_input(
            "Search Product Name",
            help="Enter product name to filter"
        ).strip().lower()
        
        # æ ¹æ®è¾“å…¥çš„äº§å“åç§°åŠ¨æ€æ›´æ–°ä¸‹æ‹‰é€‰é¡¹
        available_product_names = sorted(df['product-name'].unique())
        filtered_product_names = [name for name in available_product_names if product_name_search in name.lower()]
        selected_product_name = st.sidebar.selectbox(
            "Select Product Name",
            options=filtered_product_names,
            index= 0 if filtered_product_names else -1  # ä¸è®¾é»˜è®¤å€¼
        )
        
        # å•ç‹¬çš„ SKU æœç´¢æ¡†
        sku_search = st.sidebar.text_input(
            "Search SKU",
            help="Enter SKU to filter"
        ).strip().lower()
        
        # type åˆ—ç­›é€‰ï¼Œä½¿ç”¨æä¾›çš„é€‰é¡¹
        available_types = [
            "(Blanks)", "A-to-z Guarantee Claim", "Adjustment", "Chargeback Refund",
            "FBA Customer Return Fee", "FBA Inventory Fee", "FBA Transaction fees",
            "Liquidations", "Liquidations Adjustments", "Order", "Order_Retrocharge",
            "Refund", "Refund_Retrocharge", "Service Fee", "Shipping Services", "Transfer"
        ]
        selected_types = st.sidebar.multiselect(
            "Select Types",
            options=available_types,
            default=["Order"]  # é»˜è®¤é€‰æ‹© "Order"
        )
        
        # ä½¿ç”¨æ»‘åŠ¨æ¡é€‰æ‹©å±•ç¤ºé”€é‡å‰ N çš„ SKU
        top_n = st.sidebar.slider(
            "Select Top N SKUs to Display",
            min_value=1,
            max_value= len(df['sku'].unique()),  # å‡è®¾æœ€å¤šå±•ç¤º 20 ä¸ª SKU
            value=5  # é»˜è®¤é€‰æ‹©å‰ 5 ä¸ª SKU
        )
        
        # è¿‡æ»¤æ•°æ®
        df_filtered = df[
            (df['sku'].isin(selected_skus) | df['sku'].str.contains(sku_search, case=False, na=False)) &
            (df['month_only'].isin(selected_months)) &
            (df['year'] == selected_years) &
            (df['type'].isin(selected_types))  # æ ¹æ®é€‰æ‹©çš„ç±»å‹è¿›è¡Œç­›é€‰
        ]
        
        # ç§»é™¤ SKU ä¸º NaN çš„è¡Œ
        df_filtered = df_filtered[df_filtered['sku'].notna()]

   
        
        if df_filtered.empty:
            st.warning('No data matches your filter criteria')
            return
        
        # ç»Ÿè®¡æ¯ä¸ª SKU çš„æ¯ä¸ªæœˆçš„é”€é‡
        monthly_sales = df_filtered.groupby(['year', 'month_only', 'sku']).agg(
            total_sales=('quantity', 'sum')
        ).reset_index()

        # è·å–é”€é‡å‰ N çš„ SKU
        top_skus = monthly_sales.groupby('sku')['total_sales'].sum().nlargest(top_n).index
        monthly_sales_top = monthly_sales[monthly_sales['sku'].isin(top_skus)]

        # åˆ›å»ºé€è§†è¡¨ä»¥ä¾¿äºç»˜å›¾
        pivot_sales = monthly_sales_top.pivot_table(
            index='month_only',  # Y è½´åªå±•ç¤ºæœˆä»½
            columns='sku',
            values='total_sales',
            fill_value=0
        )
        # ç»˜åˆ¶æœˆåº¦çƒ­å›¾
        plt.figure(figsize=(12, 6))
        sns.heatmap(pivot_sales, cmap='YlGnBu', annot=True, fmt='g', linewidths=.5)
        plt.title(f'Monthly Sales Heatmap by SKU (Top {top_n})')
        plt.xlabel('SKU')
        plt.ylabel('Month')
        st.pyplot(plt)
         
        # ç»Ÿè®¡æ¯ä¸ª SKU çš„æ¯ä¸ªå°æ—¶çš„é”€é‡
        hourly_sales = df_filtered.groupby(['year', 'hour_only', 'sku']).agg(
            total_sales=('quantity', 'sum')
        ).reset_index()

        # è·å–é”€é‡å‰ N çš„ SKU
        top_skus = hourly_sales.groupby('sku')['total_sales'].sum().nlargest(top_n).index
        hourly_sales_top = hourly_sales[hourly_sales['sku'].isin(top_skus)]

        # åˆ›å»ºé€è§†è¡¨ä»¥ä¾¿äºç»˜å›¾
        pivot_sales_hour = hourly_sales_top.pivot_table(
            index='hour_only',  # Y è½´åªå±•ç¤ºæœˆä»½
            columns='sku',
            values='total_sales',
            fill_value=0
        )
        # ç»˜åˆ¶å°æ—¶çƒ­å›¾
        plt.figure(figsize=(12, 6))
        sns.heatmap(pivot_sales_hour, cmap='YlGnBu', annot=True, fmt='g', linewidths=.5)
        plt.title(f'Hourly Sales Heatmap by SKU (Top {top_n})')
        plt.xlabel('SKU')
        plt.ylabel('Hour')
        st.pyplot(plt)

        #    # åˆ›å»ºé€è§†è¡¨ä»¥ä¾¿äºç»˜å›¾
        # pivot_sales = hourly_sales_top.pivot_table(
        #     index='month_only',  # Y è½´åªå±•ç¤ºæœˆä»½
        #     columns='sku',
        #     values='total_sales',
        #     fill_value=0
        # )

       
        # # åˆ›å»ºåŸå§‹é€è§†è¡¨ä»¥ä¾¿äºç»˜å›¾ï¼Œç»Ÿè®¡æ¯ç§ç±»å‹çš„é”€é‡
        # heatmap_data = df_filtered.pivot_table(
        #     index='hour_only',  # Y è½´å±•ç¤ºæœˆä»½
        #     columns='sku',  # X è½´å±•ç¤º SKU
        #     values='quantity',  # æ•°é‡
        #     aggfunc='sum',  # èšåˆå‡½æ•°ï¼Œç»Ÿè®¡æ¯ç§ç±»å‹çš„é”€é‡
        #     fill_value=0  # å¡«å……ç¼ºå¤±å€¼ä¸º 0
        # )
        #  # åˆ›å»ºé€è§†è¡¨ï¼ŒæŒ‰å°æ—¶å’Œ SKU èšåˆ
        # hourly_sales = df.groupby(['hour', 'sku']).agg(
        #     total_sales=('quantity', 'sum')
        # ).reset_index()

       
        # # ç»˜åˆ¶å°æ—¶çº§åˆ«çš„çƒ­åŠ›å›¾
        # if not hourly_sales.empty:  # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        #     heatmap_data = hourly_sales.pivot(index='hour', columns='sku', values='total_sales')
        #     plt.figure(figsize=(12, 6))
        #     sns.heatmap(heatmap_data, annot=True, fmt=".1f", cmap='YlGnBu')
        #     plt.title(f'Hourly Sales Heatmap')
        #     plt.xlabel('SKU')
        #     plt.ylabel('Hour of the Day')
        #     st.pyplot(plt)
        # else:
        #     st.warning("No data available for the selected date.")

    except Exception as e:
        st.error(f"Error processing data: {str(e)}")
        raise e

        # å…¶ä»–å›¾åƒå±•ç¤ºï¼ˆå¦‚å°æ—¶é”€å”®é¢çš„çƒ­å›¾ï¼‰
        if not hourly_sales.empty:  # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            plt.figure(figsize=(12, 6))
            sns.heatmap(hourly_sales.pivot(index='hour', columns='total_sales', values='total_quantity'), annot=True, fmt=".1f", cmap='YlGnBu')
            plt.title(f'Hourly Sales Heatmap ')
            plt.xlabel('Total Sales')
            plt.ylabel('Hour of the Day')
            st.pyplot(plt)
        else:
            st.warning("No data available for the selected date.")

        # ç»Ÿè®¡æ¯ç§ type çš„è®¢å•æ•°é‡å’Œé”€å”®é¢
        order_counts = df_filtered.groupby(['sku', 'type']).agg(
            order_count=('quantity', 'sum'),  # ç»Ÿè®¡æ¯ç§ç±»å‹çš„è®¢å•æ•°é‡
            total_sales=('quantity', 'sum')  # ç»Ÿè®¡æ¯ç§ç±»å‹çš„é”€å”®é¢
        ).reset_index()

        # è®¡ç®—å‡€é”€å”®é‡
        net_sales = df_filtered.groupby('sku').agg(
            net_sales=('quantity', lambda x: x[df_filtered['type'] == 'Order'].sum() - x[df_filtered['type'] == 'Refund'].sum())
        ).reset_index()

        # åˆå¹¶è®¢å•æ•°é‡ã€é”€å”®é¢å’Œå‡€é”€å”®é‡
        order_counts = order_counts.merge(net_sales, on='sku', how='left')

        # è·å–é”€é‡å‰ N çš„ SKU
        top_skus = order_counts.groupby('sku')['order_count'].sum().nlargest(top_n).index
        order_counts_top = order_counts[order_counts['sku'].isin(top_skus)]

        # ç»˜åˆ¶æŸ±çŠ¶å›¾ï¼Œä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ä¸åŒç±»å‹
        plt.figure(figsize=(12, 6))
        palette = sns.color_palette("husl", len(selected_types))  # ä½¿ç”¨ä¸åŒé¢œè‰²
        for i, t in enumerate(selected_types):
            subset = order_counts_top[order_counts_top['type'] == t]
            bars = plt.bar(subset['sku'], subset['order_count'], color=palette[i], label=t)

            # åœ¨æ¯ä¸ªæŸ±å­ä¸Šæ·»åŠ æ•°é‡æ ‡ç­¾
            for bar in bars:
                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), round(bar.get_height(), 2), ha='center', va='bottom')

        # åœ¨æ ‡é¢˜ä¸­åŒºåˆ†ä¸åŒç±»å‹
        plt.title(f'Total Orders by SKU (Top {top_n}) - Types: {", ".join(selected_types)}')
        plt.xlabel('SKU')
        plt.ylabel('Order Count')
        plt.xticks(rotation=45)
        plt.legend(title='Type')

        st.pyplot(plt)
    
        # åˆ›å»ºåŸå§‹é€è§†è¡¨ä»¥ä¾¿äºç»˜å›¾ï¼Œç»Ÿè®¡æ¯ç§ç±»å‹çš„é”€é‡
        heatmap_data = df_filtered.pivot_table(
            index='month_only',  # Y è½´å±•ç¤ºæœˆä»½
            columns='sku',  # X è½´å±•ç¤º SKU
            values='quantity',  # æ•°é‡
            aggfunc='sum',  # èšåˆå‡½æ•°ï¼Œç»Ÿè®¡æ¯ç§ç±»å‹çš„é”€é‡
            fill_value=0  # å¡«å……ç¼ºå¤±å€¼ä¸º 0
        )

        # ä»…åœ¨åŒæ—¶é€‰æ‹© Order å’Œ Refund æ—¶åˆ›å»ºæ–°çš„é€è§†è¡¨è®¡ç®—å‡€é”€å”®é‡
        if "Order" in selected_types and "Refund" in selected_types:
            net_sales_data = df_filtered.pivot_table(
                index='month_only',
                columns='sku',
                values='quantity',
                aggfunc=lambda x: x[df_filtered['type'] == 'Order'].sum() - x[df_filtered['type'] == 'Refund'].sum(),
                fill_value=0
            )

            # è¿‡æ»¤å‡€é”€å”®é‡æ•°æ®ä»¥åŒ¹é…ç”¨æˆ·é€‰æ‹©çš„ SKU
            net_sales_data = net_sales_data.loc[:, net_sales_data.columns.isin(selected_skus)]

            # ç¡®ä¿åªä¿ç•™ç”¨æˆ·é€‰æ‹©çš„ SKU
            if not net_sales_data.empty:
                # ç»˜åˆ¶å‡€é”€å”®é‡çƒ­åŠ›å›¾
                plt.figure(figsize=(12, 6))
                sns.heatmap(net_sales_data, annot=True, fmt='.2f', cmap='YlGnBu', cbar_kws={'label': 'Net Sales'})
                plt.title('Net Sales by Month and SKU')
                plt.xlabel('SKU')
                plt.ylabel('Month')
                plt.xticks(rotation=45)
                st.pyplot(plt)
        else:
            st.warning('Please select both Order and Refund to display the net sales heatmap.')
   

    except Exception as e:
        st.error(f"Error processing data: {str(e)}")
        raise e

if __name__ == "__main__":
    main()